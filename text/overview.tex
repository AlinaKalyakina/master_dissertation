\section{Обзор существующих решений рассматриваемой зада­чи или ее модификаций}
Рассмотрим существующие подходы к задаче обнаружения инсайдерских угроз, сделаем их сравнение. Как уже было описано ранее, поведенческие данные можно разделить на два вида: контент --- неструктурированные данные и контекст --- структурированные. В литуратуре можно встретить подходы использующие только контент(\cite{rules}, \cite{absa}), только контекст(\cite{lac}, \cite{granual}, \cite{lstm_cnn}, \cite{gru}) и использующие оба вида(\cite{anomalyalgo}, \cite{suites}) поведенческих данных.

В первом разделе рассмотрим предлагаемые в литературе подходы к решению задачи обнаружения инсайдеров. Затем обратим особое внимание на способы использования в работах контентной составляющей поведенческих данных, сравним используемые в различных работах подходы. В конце, рассмотрим существующие для данной работы наборы данных.
\subsection{Обзор существующих подходов}

Базовый подход к любой задаче обнаружения чего-либо - придумать правила. Так поступили авторы \cite{rules}. В этой работе была предложена иерархия инсайдеров и определены присущие им черты характера. Затем по контенту пользовательского поведения с помощью сервиса IBM Personality Insights были определены черты характера пользователей, которые классифицировались по предложенным правилам. 

Задача обнаружения инсайдерских угроз может быть рассмотрена с двух сторон: как задача обнаружения аномалий, и как задача обучения с учителем. Оба имеют недостатки: 
\begin{itemize}
\item Не каждое аномальное поведение представляет собой угрозу. 
\item Для обучения алгоритма с учителем необходима разметка. На данный момент есть проблема с размеченными наборами данных. 
\end{itemize}

Таккже заметим, что поведение пользователя представляет собою последовательность его действий, напоминающую текст. Поэтому во многих работах применяются хорошо показавшие себя на задачах обработки естественного языка (англ. NLP - Natural Language Processing) идеи: использование рекуррентных нейросетей, использование механизма внимания (англ. Attention).  

\subsubsection{Обнаружение инсайдеров как задача поиска аномалий}

В \cite{lac} авторы для каждого сотрудника обучили LSTM-автокодировщик его ``нормальному'' поведению, а также построили ``граф''  сообщества пользователей, в котором ребра - общение с помощью писем . Затем они разделили всех пользователей на непересекающиеся сообщества Лувенским методом\cite{louvain} и посчитали среднюю ошибку реконструкции для каждого пользователя на всех обученных маделях его группы. Чем больше эта ошибка, тем более аномально поведение пользователя.

В \cite{anomalyalgo} авторы моделируют поведение каждого пользователя с трех сторон:
\begin{itemize}
\item Аггрегация дневной активности - контекст пользовательского поведения за каждый день
\item LDA-моделирование контента электронных писем
\item Положение пользователя в грае коммуникации внутри компании
\end{itemize}
Затем применяют четыре алгоритма детекции аномалий:
\begin{itemize}
\item Метод главных компонент. В качестве значения аномалий использовалась ошибка реконструкции.
\item Метод К ближайших соседей.
\item Оценка параметров нормального распределения на тренировочной выборке и последующая оценка вероятности того, что новые наблюдения принадлежат оцененному распределению.
\item Оценка плотности распределения окном Парзена и последующая оценка вероятности принадлежности новых наблюдений данному.
\end{itemize}

В работе \cite{ocsvm} для нахождения аномалий также использовались классические алгоритмы: Изолирующий лес и Однокласовый метод опорных векторов, агрегация производилась по нескольким промежуткам времени. Авторы попытались учесть последовательных характер поведения пользователей: строилось несколько моделей по периодам времени и каждая последующая модель получала особый \textit{trust score} от предыдущий модели.

В работе \cite{absa} использовался только контент поведенческих данных: применяется аспектно-ориентированный анализ эмоциональной окраски (англ. ABSA --- Aspect-based sentiment analysis) на контентных поведенческих данных с помощью собственной сложной рекурретной модели Для обнаружения аномалий используется Изолирующий лес.

В работе \cite{attention} авторы исследовали применение механизма внимания для RNN, GRU и LSTM архитектур для обнаружения инсайдерских угроз. Как показали эксперименты, наилучшее значение ROC AUC показало применение механизма внимания для RNN и LSTM сетей.


\subsubsection{Обнаружение инсайдеров как задача обучения с учителем}

В \cite{suites} авторы пробуют применить порядка сорока методов классификации и приходят к выводу, что лучше всего в этой задаче себя показывает случайный лес. В качестве признакового пространства в работе использовались эмоциональный факторы из писем и контекстные данные. Инетересно, что пользоватлеи классифицировались сразу на пять классов: добропорядочный, бывший работник, вор, тот, кто сливает информацию, и саботажник.

В \cite{granual} авторы пробуют применить сразу четыре алгоритма обучения с учителем: Логистическую регрессию, Случайный лес, Нейронную сеть(архитектура не показана) и XGBoost. В работе используются только контекстные поведенческие данный, которые агрегируются на разных масштабах: от недели до N действий пользователя в течение сессии. Авторы исследуют эффективность агрегации контекста пользователя на разных промежутках времени и приходят к выводу, что наиболее эффективно аггрегировать поведенческий контекст в течение сессии или рабочего дня.

В \cite{lstm_cnn} предлагается двухэтапный подход: сначала авторы обучают LSTM-сеть поведению пользователей, а затем извлекают из нее признаки и подают их на вход сверточной сети-классификатору.
В \cite{cnn_lstm} авторы применяют обратный подход: сначала сверточной сетью извлекаются признаки, а затем они подаются на вход рекуррентному классификатору с LSTM-ячейками. 

Еще один нейросетевой подход описывается в \cite{gru}. Для обнаружения инсайдеров предлагается применять GRU-классификатор.

Оригинальный подход предложен в \cite{imagebased}. В работе авторы сконструировали 20 признаков из контекстных поведенческих данных преложенным в \cite{8444978} способе. Затем по вектору признаков составили изображение: значения признаков перевели в диапазон 0-255 и растянули в изображение 32х32. Для классификации доучивались предобученные VGG16, Inception и Mobilenet на полученных изображениях.


\subsubsection{Подходы к работе с контекстом}
One-hot, агрегация, из статьи \cite{8444978}

\subsubsection{Подходы к работе с контентом}

Если контекст достаточно агрегировать и закодировать, то контент имеет сликом большой объем для простого кодирования я виде последовательности. Рассмотрим встречающиеся в литературе подходы к использованию контента.

В работе \cite{absa} использовался аспектно-ориентированный анализ эмоциональной окраски(ABSA)для получения представления контентных данных. В первом случае использовалась современная нейросетевая рекуррентная модель с механизмом внимания.

В работе \cite{suites} использовался список AFINN-111 для определения настроений\cite{nielsen11} содержимого писем и посещенных сайтов в течение месяца и формировался общий индекс риска для содержимого писем и сайтов соответственно.

В работе \cite{anomalyalgo} авторы применяли LDA модель для тематического моделирования содержимого пользовательских писем. Каждое письмо представлется вектором из 50 тематик и входит в "контентную" модель пользовательского поведения, затем для этих векторов применялись описанные выше алгоримы обнаружения аномалий.


\subsubsection{Сравнение работ}
В таблицах \ref{table:1} и \ref{table:2} показано общее сравненние рассмотренных подходов. Сравнение приведенного в статьях качества сложно сделать из-за разных версий наборов данных, разных постановок экспериментов и различных метрик качества.

\begin{table}
\caption{Сравнение статей, рассматривающих задачу обнаружения инсайдеров, как задачу поиска аномалий}
\label{table:1} 
\begin{tabular}{|m{2cm}|m{2cm}|m{2cm}|m{2cm}|p{2cm}|p{2cm}|}
\hline 
Статья & Контент & Контекст & Метод обнаружения & Наборы данных для тестирования & Качество \\ 
\hline 
LAC\cite{lac} & - & + & Вычисление ошибки реконструкции LSTM AUTOENCODER& CERT v6.2 & ??? \\ 
\hline 
Behavior Modeling + Anomaly Detection \cite{anomalyalgo} & + & + & KNN, PCA, статистических методов & CERT v6.2 & • \\ 
\hline 
ABSA model + IF \cite{absa} & + & - & Изолирующий лес & Enron, Enron+ & • \\ 
\hline 
Attention-based \cite{attention} & - & + & • & CERT v4.2 & • \\ 
\hline 
Trust aware unsupervised \cite{ocsvm} & - & + & One Class SVM, Isolation Forest & CERT v4.2 & • \\ 
\hline 
\end{tabular}
\end{table}

\begin{table}
\caption{Сравнение статей, рассматривающих задачу обнаружения инсайдеров, как задачу обучения с учителем}
\label{table:2} 
\begin{tabular}{|m{2cm}|m{2cm}|m{2cm}|m{2cm}|p{2cm}|p{2cm}|}
\hline 
Статья & Контент & Контекст & Метод обнаружения & Наборы данных для тестирования & Качество \\ 
\hline 
LSTM + CNN \cite{lstm_cnn} & - & + & CNN-классификатор & CERT v4.2 & AUC=0.9449 \\ 
\hline 
CNN + LSTM \cite{cnn_lstm} & - & + & Классификатор скрытого состояния LSTM & CERT r4.2 & • \\ 
\hline 
Analyzing Data Granularity Levels for Insider Threat Detection using Machine Learning \cite{granual} & - & + & LogReg, Random Forest, NN и XGBoost & CERT r5.2 - тренировка, CERT r5.1, r6.2 - тест   & • \\ 
\hline 
GRU \cite{gru} & - & + & GRU-классификатор & CERT v4.2 & точность - 0.92 \\ 
\hline 
Classifier Suites \cite{suites} & + & + & Порядка 40 классических классификаторов & CERT v4.2 & • \\ 
\hline 
Image-Based features \cite{imagebased} & - & + & CNN-классификатор & CERT v4.2 & • \\ 
\hline
\end{tabular}
\end{table}

\subsection{Обзор наборов данных}
\label{sec:sample}
\clearpage
