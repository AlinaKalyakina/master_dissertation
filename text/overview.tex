\section{Обзор существующих решений рассматриваемой зада­чи или ее модификаций}
Рассмотрим существующие подходы к задаче обнаружения инсайдерских угроз, сделаем их сравнение. Как уже было описано ранее, поведенческие данные можно разделить на два вида: контент --- неструктурированные данные и контекст --- структурированные. В литуратуре можно встретить подходы использующие только контент(\cite{rules}, \cite{absa}), только контекст(\cite{lac}, \cite{granual}, \cite{lstm_cnn}, \cite{gru}) и использующие оба вида(\cite{anomalyalgo}, \cite{suites}) поведенческих данных.

В первом разделе рассмотрим предлагаемые в литературе подходы к решению задачи обнаружения инсайдеров. Затем обратим особое внимание на способы использования в работах контентной составляющей поведенческих данных, сравним используемые в различных работах подходы. В конце, рассмотрим существующие для данной работы наборы данных.
\subsection{Обзор существующих подходов}

Базовый подход к любой задаче обнаружения чего-либо - придумать правила. Так поступили авторы \cite{rules}. В этой работе была предложена иерархия инсайдеров и определены присущие им черты характера. Затем по контенту пользовательского поведения с помощью сервиса IBM Personality Insights были определены черты характера пользователей, которые классифицировались по предложенным правилам. 

Задача обнаружения инсайдерских угроз может быть рассмотрена с двух сторон: как задача обнаружения аномалий, и как задача обучения с учителем. Оба имеют недостатки: 
\begin{itemize}
\item Не каждое аномальное поведение представляет собой угрозу. 
\item Для обучения алгоритма с учителем необходима разметка. На данный момент есть проблема с размеченными наборами данных. 
\end{itemize}

Таккже заметим, что поведение пользователя представляет собою последовательность его действий, напоминающую текст. Поэтому во многих работах применяются хорошо показавшие себя на задачах обработки естественного языка (англ. NLP - Natural Language Processing) идеи: использование рекуррентных нейросетей, использование механизма внимания (англ. Attention).  

\subsubsection{Обнаружение инсайдеров как задача поиска аномалий}

В \cite{lac} авторы для каждого сотрудника обучили LSTM-автокодировщик его ``нормальному'' поведению, а также построили ``граф''  сообщества пользователей, в котором ребра - общение с помощью писем . Затем они разделили всех пользователей на непересекающиеся сообщества Лувенским методом\cite{louvain} и посчитали среднюю ошибку реконструкции для каждого пользователя на всех обученных маделях его группы. Чем больше эта ошибка, тем более аномально поведение пользователя.

В \cite{anomalyalgo} авторы моделируют поведение каждого пользователя с трех сторон:
\begin{itemize}
\item Аггрегация дневной активности - контекст пользовательского поведения за каждый день
\item LDA-моделирование контента электронных писем
\item Положение пользователя в грае коммуникации внутри компании
\end{itemize}
Затем применяют четыре алгоритма детекции аномалий:
\begin{itemize}
\item Метод главных компонент. В качестве значения аномалий использовалась ошибка реконструкции.
\item Метод К ближайших соседей.
\item Оценка параметров нормального распределения на тренировочной выборке и последующая оценка вероятности того, что новые наблюдения принадлежат оцененному распределению.
\item Оценка плотности распределения окном Парзена и последующая оценка вероятности принадлежности новых наблюдений данному.
\end{itemize}

В работе \cite{ocsvm} для нахождения аномалий также использовались классические алгоритмы: Изолирующий лес и Однокласовый метод опорных векторов, агрегация производилась по нескольким промежуткам времени. Авторы попытались учесть последовательных характер поведения пользователей: строилось несколько моделей по периодам времени и каждая последующая модель получала особый \textit{trust score} от предыдущий модели.

В работе \cite{absa} использовался только контент поведенческих данных: применяется аспектно-ориентированный анализ эмоциональной окраски (англ. ABSA --- Aspect-based sentiment analysis) на контентных поведенческих данных с помощью собственной сложной рекурретной модели Для обнаружения аномалий используется Изолирующий лес.

В работе \cite{attention} авторы исследовали применение механизма внимания для RNN, GRU и LSTM архитектур для обнаружения инсайдерских угроз. Как показали эксперименты, наилучшее значение ROC AUC показало применение механизма внимания для RNN и LSTM сетей.


\subsubsection{Обнаружение инсайдеров как задача обучения с учителем}

В \cite{suites} авторы пробуют применить порядка сорока методов классификации и приходят к выводу, что лучше всего в этой задаче себя показывает случайный лес. В качестве признакового пространства в работе использовались эмоциональный факторы из писем и контекстные данные. Инетересно, что пользоватлеи классифицировались сразу на пять классов: добропорядочный, бывший работник, вор, тот, кто сливает информацию, и саботажник.

В \cite{granual} авторы пробуют применить сразу четыре алгоритма обучения с учителем: Логистическую регрессию, Случайный лес, Нейронную сеть(архитектура не показана) и XGBoost. В работе используются только контекстные поведенческие данный, которые агрегируются на разных масштабах: от недели до N действий пользователя в течение сессии. Авторы исследуют эффективность агрегации контекста пользователя на разных промежутках времени и приходят к выводу, что наиболее эффективно аггрегировать поведенческий контекст в течение сессии или рабочего дня.

В \cite{lstm_cnn} предлагается двухэтапный подход: сначала авторы обучают LSTM-сеть поведению пользователей, а затем извлекают из нее признаки и подают их на вход сверточной сети-классификатору.
В \cite{cnn_lstm} авторы применяют обратный подход: сначала сверточной сетью извлекаются признаки, а затем они подаются на вход рекуррентному классификатору с LSTM-ячейками. 

Еще один нейросетевой подход описывается в \cite{gru}. Для обнаружения инсайдеров предлагается применять GRU-классификатор.

Оригинальный подход предложен в \cite{imagebased}. Затем по вектору признаков составили изображение: значения признаков перевели в диапазон 0-255 и растянули в изображение 32х32. Для классификации доучивались предобученные VGG16, Inception и Mobilenet на полученных изображениях.

При подходе к задаче обнаружения инсайдеров как к задаче обучения с учителем возникает проблема дисбаланса классов: примеров инсайдеров в синтетических наборах данных очень мало, а в реальной жизни их еще меньше.

\subsubsection{Подходы к работе с контекстом}

Контекстные пользовательские данные структурированы.
При работе с действиями пользователей как последовательностью в большинстве работ(\cite{gru}) используется простое one-hot кодирование действий пользователя, а затем с помощью какого-либо алгоритма признаки в таком представлении переводятся в некоторое другое признаковое пространство.

В работах \cite{granual}, \cite{suites} и \cite{ocsvm} аггрегируются частоты и статистики по действиям пользователя за различные промежутки полученные таким образом векторы выступают признаками, к которым применяются классификаторы.

В работе \cite{anomalyalgo} поступали похожим образом: признаки представляли собой количество раз, которое пользователь совершил действие определенного вида в течение дня. Затем для каждой должности было определено свое множество "информативных" признаков: авторы оценивали параметры нормального распределения для переменной для роли и включали эту переменную в качестве входной переменной, если хотя бы одна из аномальных активностей находилась в области отклонения с уровнем значимости = 0,1.

В работе \cite{lstm_cnn} LSTM-сеть обучалась предсказывать по one-hot закодированному действию пользователя его следудующее действие. В качестве признаков для классфикатора бралась матрица из внутренних векторов последнего LSTM слоя.

В работах \cite{cnn_lstm} и \cite{attention} в качестве последовательностей рассматривались действия пользователя в течение рабочей сессии и в течение дня соответственнно. Эти последовательности использовались для тренировки матрицы эмбеддингов, с помощью которой действия кодировались перед подачей классификатору.

В работе \cite{imagebased} были взяты 20 признаков, упоминающихся в \cite{scenario} признаков. Агрегированные за день признаки приводятся к числам от 0 до 255 и растягиваются в изображение в градациях серого размером 32х32 - это и есть представление признаков пользователя.

Интересное использование контекстных данных предложено в работах \cite{lac} и \cite{anomalyalgo}: данные электронной почты используются для составления "графа коммуникации" пользователей. В первой работе граф используется для разделения пользователей на непересекающиеся сообщества, во второй - для получения таких признаков пользователей как: индекс Жаккара и центральность по посредничеству.

\subsubsection{Подходы к работе с контентом}

Если контекст достаточно агрегировать и закодировать, то контент имеет сликом большой объем для простого кодирования в виде последовательности. Рассмотрим встречающиеся в литературе подходы к использованию контента.

В работе \cite{absa} использовался аспектно-ориентированный анализ эмоциональной окраски(ABSA)для получения представления контентных данных. В первом случае использовалась современная нейросетевая рекуррентная модель с механизмом внимания.

В работе \cite{suites} использовался список AFINN-111 для определения настроений\cite{nielsen11} содержимого писем и посещенных сайтов в течение месяца и формировался общий индекс риска для содержимого писем и сайтов соответственно.

В работе \cite{anomalyalgo} авторы применяли LDA модель для тематического моделирования содержимого пользовательских писем. Каждое письмо представлется вектором из 50 тематик и входит в "контентную" модель пользовательского поведения, затем для этих векторов применялись описанные выше алгоримы обнаружения аномалий.

\subsubsection{Сравнение работ}
В таблицах \ref{table:1} и \ref{table:2} показано общее сравненние рассмотренных подходов. Сравнение приведенного в статьях качества сложно сделать из-за разных версий наборов данных, разных постановок экспериментов и различных метрик качества.

\begin{table}[!h]
\caption{Сравнение статей, рассматривающих задачу обнаружения инсайдеров, как задачу поиска аномалий}
\label{table:1} 
\begin{tabular}{|m{2cm}|m{2cm}|m{2cm}|m{2cm}|p{2cm}|p{2cm}|}
\hline 
Статья & Контент & Контекст & Метод обнаружения & Наборы данных для тестирования & Качество \\ 
\hline 
LAC\cite{lac} & - & + & Вычисление ошибки реконструкции LSTM AUTOENCODER& CERT v6.2 & ??? \\ 
\hline 
Behavior Modeling + Anomaly Detection \cite{anomalyalgo} & + & + & KNN, PCA, статистических методов & CERT v6.2 & • \\ 
\hline 
ABSA model + IF \cite{absa} & + & - & Изолирующий лес & Enron, Enron+ & • \\ 
\hline 
Attention-based \cite{attention} & - & + & • & CERT v4.2 & • \\ 
\hline 
Trust aware unsupervised \cite{ocsvm} & - & + & One Class SVM, Isolation Forest & CERT v4.2 & AUC = 0.93 \\ 
\hline 
\end{tabular}
\end{table}

\begin{table}[!h]
\caption{Сравнение статей, рассматривающих задачу обнаружения инсайдеров, как задачу обучения с учителем}
\label{table:2} 
\begin{tabular}{|m{2cm}|m{2cm}|m{2cm}|m{2cm}|p{2cm}|p{2cm}|}
\hline 
Статья & Контент & Контекст & Метод обнаружения & Наборы данных для тестирования & Качество \\ 
\hline 
LSTM + CNN \cite{lstm_cnn} & - & + & CNN-классификатор & CERT v4.2 & AUC=0.9449 \\ 
\hline 
CNN + LSTM \cite{cnn_lstm} & - & + & Классификатор скрытого состояния LSTM & CERT r4.2 & • \\ 
\hline 
Analyzing Data Granularity Levels for Insider Threat Detection using Machine Learning \cite{granual} & - & + & LogReg, Random Forest, NN и XGBoost & CERT r5.2 - тренировка, CERT r5.1, r6.2 - тест   & • \\ 
\hline 
GRU \cite{gru} & - & + & GRU-классификатор & CERT v4.2 & точность - 0.92 \\ 
\hline 
Classifier Suites \cite{suites} & + & + & Порядка 40 классических классификаторов & CERT v4.2 & • \\ 
\hline 
Image-Based features \cite{imagebased} & - & + & CNN-классификатор & CERT v4.2 & • \\ 
\hline
\end{tabular}
\end{table}

\subsection{Обзор наборов данных}
Сравним встречающиеся в статьях наборы данных в таблице \ref{table:3}.
\begin{table}[!h]
\caption{Сравнение популярных наборов данных}
\label{table:3}
\begin{tabular}{|m{3cm}|m{5cm}|m{3cm}|m{3cm}|}
\hline 
Название & Описание & Количество пользователей & Количество вредоносного поведения \\ 
\hline 
CERT r6.2 & Синтетический набор данных, контент сгенерирован в виде мешка слов & 4000 & 5 \\ 
\hline 
CERT r4.2 & Синтетический набор данных, контент сгенерирован в виде мешка слов  & 1000 & 70 \\ 
\hline 
TWOS\cite{twos} & Набор данных, собранный во время игры & 24 & 17 актов \\ 
\hline 
Enron\cite{enron} & Реальная переписка топ-менеджеров компании Enron & 150 & Отсутсвует \\ 
\hline 
\end{tabular} 
\end{table}

\subsection{Современные тенденции}

Как было замечено раньше, последовательность действий пользователей схожа с предложением. Поэтому применимы используемые в NLP подходы. На данном момент стал популярен механизм Self-Attention, впервые предложенный в \cite{vaswani2017attention}. Его применение в NPL улучшило качество пострения языковых моделей, а также позволило отказаться от использования рекуррентных сетей в принципе, что значительно облегчило процесс обучения.

\subsection{Выводы}
\begin{enumerate}
\item В литературе встречается два основных подхода к задаче обнаружения инсайдеров: как к задаче обучения с учителем и как к задаче детекции аномалий. 
\item В литературе встречается два подхода к работе с контентными поведенческими данными: ABSA-анализ и тематическое моделирование. Второй подход кажется более простым??? почему он?
\item Самый популярный на данный момент набор данных - CERT. 
\end{enumerate}

\label{sec:sample}
\clearpage
